{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - compatibility with Python 3\n",
    "from __future__ import print_function  # print('me') instead of print 'me'\n",
    "from __future__ import division  # 1/2 == 0.5, not 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - show figures inside the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - import common modules\n",
    "import numpy as np  # the Python array package\n",
    "import matplotlib.pyplot as plt  # the Python plotting package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - set gray colormap and nearest neighbor interpolation by default\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - import numpy.linalg with a shorter name\n",
    "import numpy.linalg as npl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - make numpy print out values in less verbose form\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - nibabel package\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - our rotations module, now on the PYTHONPATH\n",
    "from rotations import x_rotmat, y_rotmat, z_rotmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An affine normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the homework reading, we used optimization to find the translations and rotations to match two functional volumes.\n",
    "\n",
    "Now we're going to have a shot at using optimization to do an affine spatial normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First - the images.  Here is a skull-stripped version of the structural image for our familiar subject 9 from OpenFMRI dataset `ds114`.\n",
    "\n",
    "The skull-stripped version comes from the OpenFMRI dataset, but the authors have used the FSL `bet` utility to do the skull stripping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - ds114 subject 9 highres, skull stripped\n",
    "subject_img = nib.load('ds114_sub009_highres_brain_222.nii')\n",
    "subject_data = subject_img.get_data()\n",
    "subject_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example slice slicing over the third dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - an example slice of skull-stripped structural\n",
    "plt.imshow(subject_data[:, :, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNI template we want to match to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - the MNI template - also skull stripped\n",
    "template_img = nib.load('mni_icbm152_t1_tal_nlin_asym_09a_masked_222.nii')\n",
    "template_data = template_img.get_data()\n",
    "template_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - an example slice over the third dimension of the template\n",
    "plt.imshow(template_data[:, :, 42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a current mapping from the voxels in the *template* image to the voxels in the *subject* image, using the image affines.  What is that mapping (`template_vox2subject_vox`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get affine mapping from template voxels to subject voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break up this affine into the 3x3 `mat` component and length 3 `vec` translation component.  We'll need to use those in `affine_transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Break up `template_vox2subject_vox` into 3x3 `mat` and length 3 `vec`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `scipy.ndimage.affine_transform` to make a new version of the subject image, resampled into the array size / shape of the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use affine_transform to make a copy of the subject image\n",
    "# resampled into the array dimensions of the template image\n",
    "# Call this resampled copy `subject_resampled`\n",
    "# (we are going to use this array later).\n",
    "# Use order=1 for the resampling (it is quicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a slice from the resampled subject data next to the matching slice from the template using `subplots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot slice from resampled subject data next to slice from template data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to try and do an affine match between these two images, using optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to need a *cost function*.\n",
    "\n",
    "Remember, this takes the set of parameters we are using to transform the data, and returns a value that should be low when the images are well matched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value our cost function returns, is a mismatch metric.\n",
    "\n",
    "I suggest you use the correlation mismatch function for the metric.  Here is an implementation of the formula for Pearson's product-moment correlation coefficient from [wikipedia](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient):\n",
    "\n",
    "$$\n",
    "r = r_{xy} =\\frac{\\sum ^n _{i=1}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum ^n _{i=1}(x_i - \\bar{x})^2} \\sqrt{\\sum ^n _{i=1}(y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "where $\\bar{x}$ is the mean:\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\sum ^n _{i=1} x_i\n",
    "$$\n",
    "\n",
    "The correlation makes sense here, because both the subject scan and the template are T1-weighted images, meaning that we expect gray matter to be gray, white matter to be white, and CSF to be black.  So, when the images are well-matched, the signal in one image should correlate highly with the signal from matching voxels in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - the negative correlation mismatch metric\n",
    "def correl_mismatch(x, y):\n",
    "    \"\"\" Negative correlation between the two images, flattened to 1D \"\"\"\n",
    "    # Correlation\n",
    "    x_mean0 = x.ravel() - x.mean()\n",
    "    y_mean0 = y.ravel() - y.mean()\n",
    "    corr_top = x_mean0.dot(y_mean0)\n",
    "    corr_bottom = (np.sqrt(x_mean0.dot(x_mean0)) *\n",
    "                   np.sqrt(y_mean0.dot(y_mean0)))\n",
    "    return -corr_top / corr_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this gives the same answer as the standard numpy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - check numpy agrees with our negative correlation calculation\n",
    "x = np.random.normal(size=(100,))\n",
    "y = np.random.normal(size=(100,))\n",
    "assert np.allclose(correl_mismatch(x, y), -np.corrcoef(x, y)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function that will transform the subject image, given a set of transformation parameters.\n",
    "\n",
    "Let's use these transformation parameters:\n",
    "\n",
    "* `x_t` : translation in x\n",
    "* `y_t` : translation in y\n",
    "* `z_t` : translation in z\n",
    "* `x_r` : rotation around x axis\n",
    "* `y_r` : rotation around y axis\n",
    "* `z_r` : rotation around z axis\n",
    "* `x_z` : zoom (scaling) in x\n",
    "* `y_z` : zoom (scaling) in y\n",
    "* `z_z` : zoom (scaling) in z\n",
    "\n",
    "Say `vol_arr` is the image that we will transform;\n",
    "\n",
    "Our function then returns a copy of `vol_arr` with those tranformations applied.\n",
    "\n",
    "Let's also say that these transformations are in millimeters.\n",
    "\n",
    "That means we are going to make these transformations into a new 4x4 affine `P`, and compose it with the template and subject affines:\n",
    "\n",
    "* First - apply `template_vox2mm` mapping to map to millimeters;\n",
    "* Next - apply `P` affine made up of our transformations above;\n",
    "* Next - apply `mm2subject_vox`\n",
    "* Call the result `Q`.\n",
    "\n",
    "Finally, we want to apply the transformations in `Q` to make a resampled copy of the subject image.\n",
    "\n",
    "Our first task is to take the 9 parameters above, and return the affine matrix `P`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will look something like this:\n",
    "\n",
    "```\n",
    "def params2affine(params):\n",
    "    # Unpack the parameter vector to individual parameters\n",
    "    x_t, y_t, z_t, x_r, y_r, z_r, x_z, y_z, z_z = params\n",
    "    # Matrix for zooms?\n",
    "    # Matrix for rotations?\n",
    "    # Vector for translations?\n",
    "    # Build into affine\n",
    "```\n",
    "\n",
    "Hint: remember you have already imported `x_rotmat` etc from our `rotations` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make params2affine function\n",
    "# * accepts params vector\n",
    "# * builds matrix for zooms\n",
    "# * builds atrix for rotations\n",
    "# * builds vector for translations\n",
    "# * compile into affine and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - some checks that the function does the right thing\n",
    "# Identity params gives identity affine\n",
    "assert np.allclose(params2affine([0, 0, 0, 0, 0, 0, 1, 1, 1]), np.eye(4))\n",
    "# Some zooms\n",
    "assert np.allclose(params2affine([0, 0, 0, 0, 0, 0, 2, 3, 4]),\n",
    "                   np.diag([2, 3, 4, 1]))\n",
    "# Some translations\n",
    "assert np.allclose(params2affine([0, 0, 0, 0, 0, 0, 2, 3, 4]),\n",
    "                   np.diag([2, 3, 4, 1]))\n",
    "# Some rotations\n",
    "assert np.allclose(params2affine([0, 0, 0, 0, 0, 0.2, 1, 1, 1]),\n",
    "                   [[np.cos(0.2), -np.sin(0.2), 0, 0],\n",
    "                    [np.sin(0.2), np.cos(0.2), 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1],\n",
    "                    ])\n",
    "assert np.allclose(params2affine([0, 0, 0, 0, 0, 0.2, 1, 1, 1]),\n",
    "                   [[np.cos(0.2), -np.sin(0.2), 0, 0],\n",
    "                    [np.sin(0.2), np.cos(0.2), 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1],\n",
    "                    ])\n",
    "assert np.allclose(params2affine([0, 0, 0, 0, -0.1, 0, 1, 1, 1]),\n",
    "                   [[np.cos(-0.1), 0, np.sin(-0.1), 0],\n",
    "                    [0, 1, 0, 0],\n",
    "                    [-np.sin(-0.1), 0, np.cos(-0.1), 0],\n",
    "                    [0, 0, 0, 1],\n",
    "                    ])\n",
    "assert np.allclose(params2affine([0, 0, 0, 0.3, 0, 0, 1, 1, 1]),\n",
    "                   [[1, 0, 0, 0],\n",
    "                    [0, np.cos(0.3), -np.sin(0.3), 0],\n",
    "                    [0, np.sin(0.3), np.cos(0.3), 0],\n",
    "                    [0, 0, 0, 1],\n",
    "                    ])\n",
    "# Translation\n",
    "assert np.allclose(params2affine([11, 12, 13, 0, 0, 0, 1, 1, 1]),\n",
    "                   [[1, 0, 0, 11],\n",
    "                    [0, 1, 0, 12],\n",
    "                    [0, 0, 1, 13],\n",
    "                    [0, 0, 0, 1]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to make our affine `P`, we can make our cost function.\n",
    "\n",
    "The cost function should accept the same vector of parameters as `params2affine`, then:\n",
    "\n",
    "* generate `P`;\n",
    "* compose template_vox2mm, then P then mm2subject_vox to give `Q`;\n",
    "* resample the subject data using the matrix and vector from `Q` (use order=1 resampling - it is quicker);\n",
    "* return the mismatch metric for the resampled image and template.\n",
    "\n",
    "We can pick up the subject data and template data from the global namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a cost function called `cost_function` that will:\n",
    "# * accept the vector of parameters containing x_t ... z_z\n",
    "# * generate `P`;\n",
    "# * compose template_vox2mm, then P then mm2subject_vox to give `Q`;\n",
    "# * resample the subject data using the matrix and vector from `Q`.\n",
    "#   Use `order=1` for the resampling - otherwise it will be slow.\n",
    "# * return the mismatch metric for the resampled image and template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - check the cost function returns the previous value if params\n",
    "# say to do no transformation\n",
    "current = correl_mismatch(subject_resampled, template_data)\n",
    "redone = cost_function([0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
    "assert np.allclose(current, redone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to optimize.  We are going to need at least one of the cost functions from `scipy.optimize`.\n",
    "\n",
    "`fmin_powell` is a good place to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - get fmin_powell\n",
    "from scipy.optimize import fmin_powell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a callback so we can see what `fmin_powell` is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# - a callback we will pass to the fmin_powell function\n",
    "def my_callback(params):\n",
    "   print(\"Trying parameters \" + str(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `fmin_powell` with a starting guess for the parameters.  Remember to pass the callback with ``callback=my_callback``.\n",
    "\n",
    "This is going to take a crazy long time.  Maybe 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call optimizing function and collect best estimates for rotations\n",
    "# Collect best estimates in `best_params` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use these parameters to:\n",
    "\n",
    "* compile the P affine from the optimized parameters;\n",
    "* compile the Q affine from the image affines and P;\n",
    "* resample the subject image using the matrix and vector from this Q affine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# * compile the P affine from the optimized parameters;\n",
    "# * compile the Q affine from the image affines and P;\n",
    "# * resample the subject image using the matrix and vector from the Q affine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can look at the template and the resampled affine-normalized image side by side, using `subplots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show example slice from template and normalized image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
